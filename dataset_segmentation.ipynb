{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import functions\n",
    "import os\n",
    "\n",
    "#for detection/segmentation\n",
    "!#pip install ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = YOLO(\"yolov8l-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project-1/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1459.7ms\n",
      "Speed: 15.2ms preprocess, 1459.7ms inference, 12.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 1409.8ms\n",
      "Speed: 2.9ms preprocess, 1409.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1476.6ms\n",
      "Speed: 2.9ms preprocess, 1476.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1404.4ms\n",
      "Speed: 2.8ms preprocess, 1404.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 banana, 1367.6ms\n",
      "Speed: 3.2ms preprocess, 1367.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1368.0ms\n",
      "Speed: 2.8ms preprocess, 1368.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 kite, 1 banana, 1450.0ms\n",
      "Speed: 2.6ms preprocess, 1450.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s1_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1350.0ms\n",
      "Speed: 3.5ms preprocess, 1350.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_69.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1487.1ms\n",
      "Speed: 5.7ms preprocess, 1487.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1470.6ms\n",
      "Speed: 2.9ms preprocess, 1470.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_69.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1398.7ms\n",
      "Speed: 3.0ms preprocess, 1398.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s1_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1410.1ms\n",
      "Speed: 3.0ms preprocess, 1410.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1368.4ms\n",
      "Speed: 3.0ms preprocess, 1368.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s6_69.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1628.7ms\n",
      "Speed: 3.1ms preprocess, 1628.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s6_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1420.4ms\n",
      "Speed: 3.2ms preprocess, 1420.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 kite, 1 banana, 1352.6ms\n",
      "Speed: 3.0ms preprocess, 1352.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1527.3ms\n",
      "Speed: 3.1ms preprocess, 1527.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1380.8ms\n",
      "Speed: 3.6ms preprocess, 1380.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1367.6ms\n",
      "Speed: 6.0ms preprocess, 1367.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_69.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 surfboard, 1458.1ms\n",
      "Speed: 2.9ms preprocess, 1458.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 kite, 1 banana, 1399.7ms\n",
      "Speed: 105.0ms preprocess, 1399.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1386.7ms\n",
      "Speed: 4.0ms preprocess, 1386.7ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_69.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1382.4ms\n",
      "Speed: 3.0ms preprocess, 1382.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s6_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project-1/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1570.0ms\n",
      "Speed: 7.8ms preprocess, 1570.0ms inference, 12.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 banana, 1361.6ms\n",
      "Speed: 4.0ms preprocess, 1361.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/s1_69.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1370.7ms\n",
      "Speed: 4.3ms preprocess, 1370.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1484.4ms\n",
      "Speed: 6.4ms preprocess, 1484.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1535.3ms\n",
      "Speed: 2.8ms preprocess, 1535.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1376.6ms\n",
      "Speed: 5.0ms preprocess, 1376.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1380.8ms\n",
      "Speed: 8.1ms preprocess, 1380.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1517.0ms\n",
      "Speed: 2.9ms preprocess, 1517.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 banana, 1435.0ms\n",
      "Speed: 5.1ms preprocess, 1435.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/s1_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1395.2ms\n",
      "Speed: 3.0ms preprocess, 1395.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1785.3ms\n",
      "Speed: 4.1ms preprocess, 1785.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1393.0ms\n",
      "Speed: 3.4ms preprocess, 1393.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1459.6ms\n",
      "Speed: 3.0ms preprocess, 1459.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1474.9ms\n",
      "Speed: 3.1ms preprocess, 1474.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1417.5ms\n",
      "Speed: 4.5ms preprocess, 1417.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1388.0ms\n",
      "Speed: 3.1ms preprocess, 1388.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1396.2ms\n",
      "Speed: 11.6ms preprocess, 1396.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1634.8ms\n",
      "Speed: 4.3ms preprocess, 1634.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1404.7ms\n",
      "Speed: 3.0ms preprocess, 1404.7ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1387.1ms\n",
      "Speed: 4.5ms preprocess, 1387.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1593.2ms\n",
      "Speed: 6.7ms preprocess, 1593.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1418.1ms\n",
      "Speed: 3.4ms preprocess, 1418.1ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1384.1ms\n",
      "Speed: 5.8ms preprocess, 1384.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1631.9ms\n",
      "Speed: 3.1ms preprocess, 1631.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project-1/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1428.0ms\n",
      "Speed: 3.6ms preprocess, 1428.0ms inference, 13.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 1366.4ms\n",
      "Speed: 5.6ms preprocess, 1366.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1378.5ms\n",
      "Speed: 3.0ms preprocess, 1378.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1556.0ms\n",
      "Speed: 3.4ms preprocess, 1556.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1377.8ms\n",
      "Speed: 3.9ms preprocess, 1377.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1423.8ms\n",
      "Speed: 4.3ms preprocess, 1423.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1536.5ms\n",
      "Speed: 3.2ms preprocess, 1536.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n3_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1405.7ms\n",
      "Speed: 7.0ms preprocess, 1405.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_171.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1522.8ms\n",
      "Speed: 9.3ms preprocess, 1522.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_171.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1496.1ms\n",
      "Speed: 2.8ms preprocess, 1496.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1407.8ms\n",
      "Speed: 4.5ms preprocess, 1407.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1437.3ms\n",
      "Speed: 4.6ms preprocess, 1437.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1396.6ms\n",
      "Speed: 2.8ms preprocess, 1396.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1657.5ms\n",
      "Speed: 6.0ms preprocess, 1657.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n3_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1385.1ms\n",
      "Speed: 5.0ms preprocess, 1385.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1381.0ms\n",
      "Speed: 3.1ms preprocess, 1381.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1492.8ms\n",
      "Speed: 3.0ms preprocess, 1492.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project-1/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1406.1ms\n",
      "Speed: 4.5ms preprocess, 1406.1ms inference, 13.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 1375.4ms\n",
      "Speed: 18.3ms preprocess, 1375.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Overripen/n2_171.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1506.1ms\n",
      "Speed: 2.8ms preprocess, 1506.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Overripen/n3_171.jpeg\n"
     ]
    }
   ],
   "source": [
    "path_classes = [\"Green\", \"Yellowish_Green\", \"Midripen\", \"Overripen\"]\n",
    "path_folder = \"classification_cnn/nuno_nosso_dataset_cnn\"\n",
    "path_newfoler = \"classification_cnn/segcrop_nuno_nosso_dataset_cnn\"\n",
    "\n",
    "#seg_model()\n",
    "\n",
    "for rel_path_class in path_classes:\n",
    "    seg_model.predict()\n",
    "    path_class = os.path.join(path_folder, rel_path_class)\n",
    "    for rel_image_path in os.listdir(path_class):\n",
    "        image_path = os.path.join(path_class, rel_image_path)\n",
    "        if 'DS_Store' in image_path:\n",
    "            continue\n",
    "        image = plt.imread(image_path)\n",
    "        result = seg_model(image)[0]\n",
    "        boxes_classes = result.boxes.cls.numpy()\n",
    "        banana_box_idx = np.where(boxes_classes == 46.)[0]\n",
    "        if banana_box_idx.size != 1:\n",
    "            continue\n",
    "        mask = np.zeros_like(image)\n",
    "        mask = cv2.drawContours(mask, [result.masks.xy[0].astype(int)], 0, (255,255,255), -1)\n",
    "        xyxy = result.boxes.xyxy[0].numpy().astype(int)\n",
    "        seg_image = mask & image\n",
    "        crop_image = seg_image[xyxy[1]:xyxy[3], xyxy[0]:xyxy[2] ]\n",
    "        newpath = os.path.join(path_newfoler, rel_path_class, rel_image_path)\n",
    "        plt.imsave(newpath, crop_image)\n",
    "        print(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset_saranya2021/Green/g001.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-157920019fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset_saranya2021/Green/g001.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxyxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2374\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset_saranya2021/Green/g001.jpg'"
     ]
    }
   ],
   "source": [
    "image = plt.imread(\"dataset_saranya2021/Green/g001.jpg\")\n",
    "result = seg_model.predict(image)[0]\n",
    "xyxy = result.boxes.xyxy[0].numpy().astype(int)\n",
    "plt.imshow(image[xyxy[1]:xyxy[3], xyxy[0]:xyxy[2] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d59734fbeb9fca37cc515a11cf6c1101fde54de1c195f7fb5593e1b9c302c936"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
